## Curating My Questions that Test the Conceptual Understanding 
1. Suppose that we negate the weights of pre-trained neural networks, such as CNN or Transformers. Does that make a sharp decrease in performance?
    - *_Hint_*: NNs have a non-convex loss surface
2. Suppose we train NN on MNIST dataset (black bg) and test it on images that has white bg, what will happen? Does the network perform similarly or worse?
    - *_Hint_*: Out of distribution problem,
  
3. Suppose we want to make a robust model. What are all the requirements?
    - *_Hint_*: Definition for robustness first (sensitivity of the performance of the model to small changes (in something)!)
    - Elaborating the experimental setup with evaluation suite
4. Suppose you want to create a new activation function. What aspects do you consider? Why?
    - *_Hint_*: Zero ip --> zero op, normalization, initialization all prefers zero centering.
