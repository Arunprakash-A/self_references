## Curating My Questions that Test the Conceptual Understanding 
1. Suppose that we negate the weights of pre-trained neural networks, such as CNN or Transformers. Does that make a sharp decrease in performance?
    - Hint: NNs have a non-convex loss surface
2. Suppose we train NN on MNIST dataset (black bg) and test it on images that has white bg, what will happen? Does the network perform similarly or worse?
    - Hint: Out of distribution problem,
  
3. Suppose we want to make a robust model. What are all the requirements?
    - Hint: Definition for robustness first (sensitivity to small change in something!)
    - Elaborating the experimental setup with evalaution suite
